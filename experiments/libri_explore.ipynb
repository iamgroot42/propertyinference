{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "639a278f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99d559bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 10:30:40.739608: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-16 10:30:40.789286: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-16 10:30:43.188312: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_from_disk\n",
    "import distribution_inference.models.asr as models_asr\n",
    "import evaluate\n",
    "from distribution_inference.training.utils import load_model\n",
    "import numpy as np\n",
    "import torch as ch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, List, Dict, Union\n",
    "\n",
    "from transformers import WhisperFeatureExtractor\n",
    "from transformers import WhisperTokenizerFast\n",
    "from transformers import WhisperProcessor\n",
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "from audiomentations import Compose, AddGaussianNoise, PitchShift, AirAbsorption, TanhDistortion\n",
    "import IPython.display as ipd\n",
    "\n",
    "import evaluate\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75442c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_data_dir = \"/p/adversarialml/as9rw/datasets/librispeech/\"\n",
    "small_data_sample = load_from_disk(os.path.join(base_data_dir, \"processed\", \"adv\", \"audit_subjects\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "add96648",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WhisperTokenizerFast.from_pretrained(\"openai/whisper-tiny.en\")\n",
    "fe = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-tiny.en\")\n",
    "loss_fn = ch.nn.CrossEntropyLoss()\n",
    "metric = evaluate.load(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "91560c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], ch.Tensor]]]) -> Dict[str, ch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": x} for x in features[\"input_features\"]]\n",
    "        batch = self.processor.feature_extractor.pad(\n",
    "            input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": x} for x in features[\"labels\"]]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(\n",
    "            label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(\n",
    "            labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cbbd4622",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollatorSpeechSeq2SeqWithPadding(processor=WhisperProcessor.from_pretrained(\"openai/whisper-tiny.en\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "9b84a513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_changes_under_augs(data, m, tokenizer, batch_size: int, sample_rate: int = 16000):\n",
    "    transforms = [\n",
    "        AddGaussianNoise(\n",
    "            min_amplitude=0.01,\n",
    "            max_amplitude=0.015,\n",
    "            p=1.0),\n",
    "        PitchShift(\n",
    "            min_semitones=-4.0,\n",
    "            max_semitones=4.0,\n",
    "            p=1.0),\n",
    "        AirAbsorption(\n",
    "            min_distance=100,\n",
    "            max_distance=500,\n",
    "            p=1.0),\n",
    "        TanhDistortion(\n",
    "            min_distortion=0.1,\n",
    "            max_distortion=0.7,\n",
    "            p=1.0)\n",
    "    ]\n",
    "    aug_data_flat = []\n",
    "    for x in tqdm(data['audio'], \"Generating augmented data\"):\n",
    "        aug_data_flat.extend([transform(x['array'].astype(np.float32), sample_rate) for transform in transforms])\n",
    "    # Get encodings for text in data\n",
    "    all_text = data['text']\n",
    "    encodings = tokenizer([x.lower() for x in data['text']]).input_ids\n",
    "    # Get model outputs for augmented data\n",
    "    losses, wers = [], []\n",
    "    for i in tqdm(range(0, len(aug_data_flat), batch_size), desc=\"Collecting statistics\"):\n",
    "        batch = aug_data_flat[i:i+batch_size]\n",
    "        batch_data = fe(batch, sampling_rate=16_000).input_features\n",
    "        # Could make more efficient by only making forward call and using that to infer\n",
    "        # Generated sequence, but following is more fool-proof\n",
    "        \n",
    "        # Get loss values\n",
    "        labels = []\n",
    "        for j in range(batch_size):\n",
    "            if i + j >= len(aug_data_flat):\n",
    "                break\n",
    "            labels.append(encodings[(i + j) // len(transforms)])\n",
    "        collated_batch = collator({\n",
    "            \"input_features\": batch_data,\n",
    "            \"labels\": labels\n",
    "        })\n",
    "        logits = m(**collated_batch).logits.detach()\n",
    "        loss = [loss_fn(l, b).item() for l, b in zip(logits, collated_batch['labels'])]\n",
    "        losses.extend(loss)\n",
    "        \n",
    "        # Get outputs (for WER computation)\n",
    "        output = m.model.generate(input_features=collated_batch['input_features'])\n",
    "        pred_str = tokenizer.batch_decode(output, skip_special_tokens=True, normalize=True)\n",
    "        for j, pred in enumerate(pred_str):\n",
    "            if i + j >= len(aug_data_flat):\n",
    "                break\n",
    "            wers.append(metric.compute(predictions=[pred], references=[all_text[(i + j) // len(transforms)].lower()]))\n",
    "\n",
    "    losses = np.array(losses)\n",
    "    wers = np.array(wers)\n",
    "    losses = np.reshape(losses, (-1, len(transforms)))\n",
    "    wers = np.reshape(wers, (-1, len(transforms)))\n",
    "    \n",
    "    return losses, wers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "c523b9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/p/adversarialml/as9rw/models_librispeech/whisper-tiny/adv/0/0.0/2_5.6370\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "6f643608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model!\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = models_asr.WhisperTiny()\n",
    "model, (train_ids, _) = load_model(model, model_path, on_cpu=False)\n",
    "model.eval()\n",
    "print(\"Loaded model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "0829b92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_data = load_from_disk(os.path.join(base_data_dir, \"processed\", \"adv\", \"holdout_subjects\"))\n",
    "all_speaker_ids = adv_data[\"speaker_id\"]\n",
    "unique_speaker_ids = np.unique(adv_data[\"speaker_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "d943fef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pick = 5\n",
    "\n",
    "pick_in_speakers  = np.random.choice(train_ids, num_pick, replace=False)\n",
    "pick_out_speakers = np.random.choice(list(set(unique_speaker_ids) - set(train_ids)), num_pick, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "4332c172",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data_mask  = np.where(np.isin(all_speaker_ids, pick_in_speakers))[0]\n",
    "out_data_mask = np.where(np.isin(all_speaker_ids, pick_out_speakers))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "a978cda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data  = adv_data.select(in_data_mask)\n",
    "out_data = adv_data.select(out_data_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "b7df89ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating augmented data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:14<00:00,  3.42it/s]\n",
      "Collecting statistics: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [01:22<00:00,  3.31s/it]\n"
     ]
    }
   ],
   "source": [
    "losses_in, wers_in = metric_changes_under_augs(\n",
    "    in_data,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    batch_size = 8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "c8eec7ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating augmented data: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:15<00:00,  3.33it/s]\n",
      "Collecting statistics: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [01:19<00:00,  3.20s/it]\n"
     ]
    }
   ],
   "source": [
    "losses_out, wers_out = metric_changes_under_augs(\n",
    "    out_data,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    batch_size = 8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "5cf1d856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 960x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfp = 3\n",
    "\n",
    "plt.hist(losses_in[:, tfp], bins=7, label=\"Members\", alpha=0.5, density=True)\n",
    "plt.hist(losses_out[:, tfp], bins=7, label=\"Non-members\", alpha=0.5, density=True)\n",
    "plt.legend()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "037a62fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.95 | Test: 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Try training a meta-classifier on top of these metrics\n",
    "num_test = 10\n",
    "num_train = len(losses_in) - num_test\n",
    "\n",
    "X_train = np.concatenate((losses_in[num_test:], losses_out[num_test:]), 0)\n",
    "Y_train = np.array([1] * num_train + [0] * num_train)\n",
    "\n",
    "X_test = np.concatenate((losses_in[:num_test], losses_out[:num_test]), 0)\n",
    "Y_test = np.array([1] * num_test + [0] * num_test)\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=10)\n",
    "clf.fit(X_train, Y_train)\n",
    "print(\"Train:\", clf.score(X_train, Y_train), \"| Test:\", clf.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed27956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_to_device(data, device):\n",
    "    return {key: value.to(device) for key, value in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f33a675",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e43921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_metrics(m, features):\n",
    "    wer_metric = evaluate.load(\"wer\")\n",
    "\n",
    "    input_features = [{\"input_features\": x} for x in features[\"input_features\"]]\n",
    "    batch = m.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "    # get the tokenized label sequences\n",
    "    label_features = [{\"input_ids\": x} for x in features[\"labels\"]]\n",
    "    # pad the labels to max length\n",
    "    labels_batch = m.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "    # replace padding with -100 to ignore loss correctly\n",
    "    labels = labels_batch[\"input_ids\"].masked_fill(\n",
    "    labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "    # if bos token is appended in previous tokenization step,\n",
    "    # cut bos token here as it's append later anyways\n",
    "    if (labels[:, 0] == m.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "        labels = labels[:, 1:]\n",
    "\n",
    "    batch[\"labels\"] = labels\n",
    "    \n",
    "    # Get model output\n",
    "    with ch.no_grad():\n",
    "        batch_cuda = recursive_to_device(batch, \"cuda:0\")\n",
    "        logits = m.model(**batch_cuda).logits.cpu()\n",
    "        pred_ids = m.model.generate(**batch_cuda, max_length=225).cpu()\n",
    "        label_ids = batch[\"labels\"]\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = model.tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = model.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    pred_str = [x.lstrip().strip() for x in pred_str]\n",
    "    label_str = model.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "    \n",
    "    wer = [wer_metric.compute(predictions=[x], references=[y]) for (x, y) in zip(pred_str, label_str)]\n",
    "    for x, y in zip(pred_str, label_str):\n",
    "        print(x)\n",
    "        print(y)\n",
    "        print()\n",
    "\n",
    "    # Compute loss\n",
    "    loss_function = ch.nn.CrossEntropyLoss()\n",
    "    losses = [loss_function(x.view(-1, x.shape[-1]), y.view(-1)).item() for (x, y) in zip(logits, label_ids)]\n",
    "\n",
    "    return wer, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae088906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(m, data, batch_size: int = 8):\n",
    "    all_metrics = []\n",
    "    for i in tqdm(range(0, len(data), batch_size)):\n",
    "        all_metrics.append(get_batch_metrics(m, data[i:i+batch_size]))\n",
    "        break\n",
    "    all_metrics = np.concatenate(all_metrics, 0).T\n",
    "    return all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c950efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses_members = get_metrics(model, subset_members)\n",
    "losses_nonmembers = get_metrics(model, subset_nonmembers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec2374b",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_nonmembers[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d6583f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss values, WER, and CER for both scenarios\n",
    "plt.hist(losses_members, 21, alpha=0.5, label=\"members\")\n",
    "plt.hist(losses_nonmembers, 21, alpha=0.5, label=\"non-members\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97122997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later: Consider adding noise/augmentations to input and measure robustness in model behavior"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd9",
   "language": "python",
   "name": "phd9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
