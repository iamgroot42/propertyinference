{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, models\n",
    "import torch.utils.data as data\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "data_root = 'data/celeba'\n",
    "\n",
    "celeba_data = datasets.CelebA(data_root, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CelebAPairsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_root, download=True):\n",
    "        self.dataset = datasets.CelebA(data_root, download=download, transform=transform)\n",
    "\n",
    "        self.male_smiling_indices = []\n",
    "        self.male_not_smiling_indices = []\n",
    "        self.female_smiling_indices = []\n",
    "        self.female_not_smiling_indices = []\n",
    "\n",
    "        self.pairs = [] # index1, index2, pos\n",
    "\n",
    "\n",
    "        for i in range(len(self.dataset)):\n",
    "            if self.dataset.attr[i][20] == 1 and self.dataset.attr[i][31] == 1: # smiling male\n",
    "                self.male_smiling_indices.append(i)\n",
    "            elif self.dataset.attr[i][20] == 1 and self.dataset.attr[i][31] == 0: # not smiling male\n",
    "                self.male_not_smiling_indices.append(i)\n",
    "            elif self.dataset.attr[i][20] == 0 and self.dataset.attr[i][31] == 1: # smiling female\n",
    "                self.female_smiling_indices.append(i)\n",
    "            elif self.dataset.attr[i][20] == 0 and self.dataset.attr[i][31] == 0: # not smiling female\n",
    "                self.female_not_smiling_indices.append(i)\n",
    "\n",
    "        \n",
    "        # generate initial random pairs\n",
    "        for i in range(self.__len__()): # look into number of pairs\n",
    "            positive = 0\n",
    "            if random.random() > 0.5: # positive match\n",
    "                if random.random() > 0.5: # both smiling\n",
    "                    img1_index, img2_index = random.choice(self.male_smiling_indices), random.choice(self.female_smiling_indices)\n",
    "                else: # both not smiling\n",
    "                    img1_index, img2_index = random.choice(self.male_not_smiling_indices), random.choice(self.female_not_smiling_indices)\n",
    "                positive = 1\n",
    "            else: # negative match\n",
    "                # img1_index, img2_index = random.sample(self.not_smiling_indices, 2)\n",
    "                if random.random() > 0.5:\n",
    "                    img1_index, img2_index = random.choice(self.male_smiling_indices), random.choice(self.female_not_smiling_indices)\n",
    "                else:\n",
    "                    img1_index, img2_index = random.choice(self.female_smiling_indices), random.choice(self.male_not_smiling_indices)\n",
    "\n",
    "            img1, _ = self.dataset[img1_index]\n",
    "            img2, _ = self.dataset[img2_index]\n",
    "\n",
    "            self.pairs.append([img1, img2, positive])\n",
    "\n",
    "    def is_male(self, index):\n",
    "        return index in self.male_not_smiling_indices or index in self.male_smiling_indices\n",
    "\n",
    "    def is_smiling(self, index):\n",
    "        return index in self.male_smiling_indices or index in self.female_smiling_indices\n",
    "\n",
    "    def get_pair(self, index):\n",
    "        return self.pairs[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(self.male_smiling_indices), len(self.male_not_smiling_indices), len(self.female_smiling_indices), len(self.female_not_smiling_indices))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.pairs[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/18/2023 11:45:23:WARNING:The OGB package is out of date. Your version is 1.3.4, while the latest version is 1.3.6.\n",
      "0.5001: 100%|██████████| 100/100 [00:06<00:00, 15.81it/s]\n",
      "0.5000: 100%|██████████| 100/100 [00:00<00:00, 127.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# celeba_data = CelebAPairsDataset(data_root, download=False)\n",
    "# celeba_loader = torch.utils.data.DataLoader(celeba_data, batch_size=16, shuffle=True)\n",
    "from distribution_inference.datasets import utils\n",
    "from distribution_inference.config.core import TrainConfig\n",
    "\n",
    "ds_wrapper = utils.get_dataset_wrapper(\"celeba\")\n",
    "ds_info = utils.get_dataset_information(\"celeba\")\n",
    "\n",
    "data_config = TrainConfig.load(\"./matchdg_conf.json\").data_config\n",
    "\n",
    "celeba_data = ds_wrapper(data_config=data_config)\n",
    "celeba_loader, _ = celeba_data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeba_data.dataset.attr_names[31]\n",
    "celeba_data.dataset.attr_names[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of pairs from the data loader\n",
    "batch = next(iter(celeba_loader))\n",
    "\n",
    "# Extract a single pair of images from the batch\n",
    "img1, img2, pos = batch[0][0], batch[1][0], batch[2][0]\n",
    "\n",
    "print('positive: ' + str(pos))\n",
    "\n",
    "# Convert the PyTorch tensors to numpy arrays\n",
    "img1 = img1.numpy().transpose(1, 2, 0)\n",
    "img2 = img2.numpy().transpose(1, 2, 0)\n",
    "\n",
    "# Plot the images side by side\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(img1)\n",
    "ax[1].imshow(img2)\n",
    "ax[0].set_title(\"Image 1\")\n",
    "ax[1].set_title(\"Image 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/savo5444/.conda/envs/phd9/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/u/savo5444/.conda/envs/phd9/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.alexnet(pretrained=False, num_classes=128)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss funcions\n",
    "def cosine_similarity( x1, x2 ):\n",
    "    cos = torch.nn.CosineSimilarity(dim=1, eps=1e-08)\n",
    "    return cos(x1, x2)\n",
    "\n",
    "tau = 0.05 # from their code\n",
    "\n",
    "def loss_fn(x1, x2, x2_samples, y_samples):\n",
    "    # print('x1:')\n",
    "    # print(x1.shape)\n",
    "    # print('x2:')\n",
    "    # print(x2.shape)\n",
    "    # print('y_samples:')\n",
    "    # print(y_samples.shape)\n",
    "    # print('x2 samples:')\n",
    "    # print(x2_samples.shape)\n",
    "\n",
    "    sim = cosine_similarity(x1, x2)\n",
    "    e_term = torch.exp(sim / tau)\n",
    "    \n",
    "    sigma_term = 0\n",
    "\n",
    "    for i in range(len(y_samples)):\n",
    "        if y_samples[i].item() == 1: # skip positive pairs\n",
    "            continue\n",
    "        sigma_term = sigma_term + torch.exp(cosine_similarity(x1, model(x2_samples[i].unsqueeze(0).to(device))) / tau)\n",
    "\n",
    "    return -torch.log(e_term / (e_term + sigma_term))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, optimizer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "    image_i = 0\n",
    "\n",
    "    for batch, (x1_samples, x2_samples, y_samples) in enumerate(dataloader):\n",
    "\n",
    "        for i in range(len(y_samples)):\n",
    "            x1, x2, y = x1_samples[i].to(device), x2_samples[i].to(device), y_samples[i].to(device)\n",
    "            # print('Y Shape:')\n",
    "            # print(y_samples.shape)\n",
    "\n",
    "            # print('x1 samples Shape:')\n",
    "            # print(x1_samples.shape)\n",
    "\n",
    "            # print('x2 samples shape:')\n",
    "            # print(x2_samples.shape)\n",
    "\n",
    "            if y.item() == 0: # skip negative pairs\n",
    "                continue\n",
    "        \n",
    "            # Compute prediction and loss\n",
    "            model.train()\n",
    "            output1 = model(x1.unsqueeze(0)).to(device)\n",
    "            output2 = model(x2.unsqueeze(0)).to(device)\n",
    "\n",
    "            loss = loss_fn(output1, output2, x2_samples, y_samples).to(device)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if image_i % 1000 == 0:\n",
    "                last_loss = running_loss / 1000\n",
    "                # print('  pairs {} loss: {}'.format(image_i + 1, last_loss))\n",
    "                running_loss = 0.\n",
    "            \n",
    "            image_i += 1\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(output1, output2):\n",
    "    distance = torch.norm(output2 - output1)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_match_pairs():\n",
    "    for i in range(len(celeba_data.pairs)): # for each anchor pair\n",
    "        pair = celeba_data.get_pair(i)\n",
    "        x1 = pair[0].to(device) # anchor\n",
    "        output1 = model(x1.unsqueeze(0)).squeeze(0)\n",
    "        \n",
    "        if pair[2] == 0: # skip negative pairs\n",
    "            continue\n",
    "\n",
    "        is_smiling = celeba_data.is_smiling(i)\n",
    "\n",
    "        min_dist = 999\n",
    "        new_sample = None\n",
    "\n",
    "        # for k in range(len(celeba_data.pairs)): # for each pair except anchor and different classes\n",
    "        for k in range(10): # 10 for the demo\n",
    "            if i == k or is_smiling != celeba_data.is_smiling(k): # skip anchor and non same class\n",
    "                continue\n",
    "\n",
    "            p = celeba_data.get_pair(i)\n",
    "            x3, x4 = p[0].to(device), p[1].to(device)\n",
    "\n",
    "            output3 = model(x3.unsqueeze(0)).squeeze(0)\n",
    "            output4 = model(x4.unsqueeze(0)).squeeze(0)\n",
    "                \n",
    "            d1 = dist(output1, output3)\n",
    "            d2 = dist(output1, output4)\n",
    "\n",
    "            if d1 < min_dist:\n",
    "                min_dist = d1\n",
    "                new_sample = x3\n",
    "            \n",
    "            if d2 < min_dist:\n",
    "                min_dist = d2\n",
    "                new_sample = x4\n",
    "        \n",
    "        celeba_data.pairs[i][1] = new_sample.cpu()# replace second sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "running_loss = 0.\n",
    "\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    loss = train_loop(celeba_loader, model, optimizer)\n",
    "    print('Epoch {} loss: {}'.format(t + 1, loss))\n",
    "    running_loss += loss\n",
    "    print('Running loss: {}'.format(running_loss / (t + 1)))\n",
    "    \n",
    "\n",
    "    if t % 2 == 0:\n",
    "        # print('Updating match pairs...') # update match pairs\n",
    "        update_match_pairs()\n",
    "        print('Match pairs updated.')\n",
    "\n",
    "    # test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PHASE 2 (ERM PHASE)\n",
    "epochs = 10\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "running_loss = 0.\n",
    "\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    loss = train_loop(celeba_loader, model, optimizer)\n",
    "    print('Epoch {} loss: {}'.format(t + 1, loss))\n",
    "    running_loss += loss\n",
    "    print('Running loss: {}'.format(running_loss / (t + 1)))\n",
    "\n",
    "    # test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
