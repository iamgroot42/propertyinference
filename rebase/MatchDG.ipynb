{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, models\n",
    "import torch.utils.data as data\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "data_root = 'data/celeba'\n",
    "\n",
    "celeba_data = datasets.CelebA(data_root, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CelebAPairsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_root, download=True):\n",
    "        self.dataset = datasets.CelebA(data_root, download=download, transform=transform)\n",
    "\n",
    "        self.male_smiling_indices = []\n",
    "        self.male_not_smiling_indices = []\n",
    "        self.female_smiling_indices = []\n",
    "        self.female_not_smiling_indices = []\n",
    "\n",
    "        self.pairs = [] # index1, index2, pos\n",
    "\n",
    "\n",
    "        for i in range(len(self.dataset)):\n",
    "            if self.dataset.attr[i][20] == 1 and self.dataset.attr[i][31] == 1: # smiling male\n",
    "                self.male_smiling_indices.append(i)\n",
    "            elif self.dataset.attr[i][20] == 1 and self.dataset.attr[i][31] == 0: # not smiling male\n",
    "                self.male_not_smiling_indices.append(i)\n",
    "            elif self.dataset.attr[i][20] == 0 and self.dataset.attr[i][31] == 1: # smiling female\n",
    "                self.female_smiling_indices.append(i)\n",
    "            elif self.dataset.attr[i][20] == 0 and self.dataset.attr[i][31] == 0: # not smiling female\n",
    "                self.female_not_smiling_indices.append(i)\n",
    "\n",
    "        \n",
    "        # generate initial random pairs\n",
    "        for i in range(self.__len__()): # look into number of pairs\n",
    "            positive = 0\n",
    "            if random.random() > 0.5: # positive match\n",
    "                if random.random() > 0.5: # both smiling\n",
    "                    img1_index, img2_index = random.choice(self.male_smiling_indices), random.choice(self.female_smiling_indices)\n",
    "                else: # both not smiling\n",
    "                    img1_index, img2_index = random.choice(self.male_not_smiling_indices), random.choice(self.female_not_smiling_indices)\n",
    "                positive = 1\n",
    "            else: # negative match\n",
    "                # img1_index, img2_index = random.sample(self.not_smiling_indices, 2)\n",
    "                if random.random() > 0.5:\n",
    "                    img1_index, img2_index = random.choice(self.male_smiling_indices), random.choice(self.female_not_smiling_indices)\n",
    "                else:\n",
    "                    img1_index, img2_index = random.choice(self.female_smiling_indices), random.choice(self.male_not_smiling_indices)\n",
    "\n",
    "            img1, _ = self.dataset[img1_index]\n",
    "            img2, _ = self.dataset[img2_index]\n",
    "\n",
    "            self.pairs.append([img1, img2, positive])\n",
    "\n",
    "    def is_male(self, index):\n",
    "        return index in self.male_not_smiling_indices or index in self.male_smiling_indices\n",
    "\n",
    "    def is_smiling(self, index):\n",
    "        return index in self.male_smiling_indices or index in self.female_smiling_indices\n",
    "\n",
    "    def get_pair(self, index):\n",
    "        return self.pairs[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(self.male_smiling_indices), len(self.male_not_smiling_indices), len(self.female_smiling_indices), len(self.female_not_smiling_indices))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.pairs[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/18/2023 11:45:23:WARNING:The OGB package is out of date. Your version is 1.3.4, while the latest version is 1.3.6.\n",
      "0.5001: 100%|██████████| 100/100 [00:06<00:00, 15.81it/s]\n",
      "0.5000: 100%|██████████| 100/100 [00:00<00:00, 127.85it/s]\n"
     ]
    }
   ],
   "source": [
    "# celeba_data = CelebAPairsDataset(data_root, download=False)\n",
    "# celeba_loader = torch.utils.data.DataLoader(celeba_data, batch_size=16, shuffle=True)\n",
    "from distribution_inference.datasets import utils\n",
    "from distribution_inference.config.core import TrainConfig\n",
    "\n",
    "ds_wrapper = utils.get_dataset_wrapper(\"celeba\")\n",
    "ds_info = utils.get_dataset_information(\"celeba\")\n",
    "\n",
    "data_config = TrainConfig.load(\"./matchdg_conf.json\").data_config\n",
    "\n",
    "celeba_data = ds_wrapper(data_config=data_config)\n",
    "celeba_loader, _ = celeba_data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CelebaWrapper' object has no attribute 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/u/savo5444/srg_experiments/property_inference/rebase/MatchDG.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgpusrv08/u/savo5444/srg_experiments/property_inference/rebase/MatchDG.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m celeba_data\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39mattr_names[\u001b[39m31\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgpusrv08/u/savo5444/srg_experiments/property_inference/rebase/MatchDG.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m celeba_data\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mattr_names[\u001b[39m20\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CelebaWrapper' object has no attribute 'dataset'"
     ]
    }
   ],
   "source": [
    "celeba_data.dataset.attr_names[31]\n",
    "celeba_data.dataset.attr_names[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/u/savo5444/srg_experiments/property_inference/rebase/MatchDG.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgpusrv08/u/savo5444/srg_experiments/property_inference/rebase/MatchDG.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(celeba_loader))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgpusrv08/u/savo5444/srg_experiments/property_inference/rebase/MatchDG.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Extract a single pair of images from the batch\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgpusrv08/u/savo5444/srg_experiments/property_inference/rebase/MatchDG.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m img1, img2, pos \u001b[39m=\u001b[39m batch[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m], batch[\u001b[39m1\u001b[39;49m][\u001b[39m0\u001b[39;49m], batch[\u001b[39m2\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgpusrv08/u/savo5444/srg_experiments/property_inference/rebase/MatchDG.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mpositive: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(pos))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgpusrv08/u/savo5444/srg_experiments/property_inference/rebase/MatchDG.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Convert the PyTorch tensors to numpy arrays\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "# Get a batch of pairs from the data loader\n",
    "batch = next(iter(celeba_loader))\n",
    "\n",
    "# Extract a single pair of images from the batch\n",
    "img1, img2, pos = batch[0][0], batch[1][0], batch[2][0]\n",
    "\n",
    "print('positive: ' + str(pos))\n",
    "\n",
    "# Convert the PyTorch tensors to numpy arrays\n",
    "img1 = img1.numpy().transpose(1, 2, 0)\n",
    "img2 = img2.numpy().transpose(1, 2, 0)\n",
    "\n",
    "# Plot the images side by side\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax[0].imshow(img1)\n",
    "ax[1].imshow(img2)\n",
    "ax[0].set_title(\"Image 1\")\n",
    "ax[1].set_title(\"Image 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/savo5444/.conda/envs/phd9/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/u/savo5444/.conda/envs/phd9/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.alexnet(pretrained=False, num_classes=128)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss funcions\n",
    "def cosine_similarity( x1, x2 ):\n",
    "    cos = torch.nn.CosineSimilarity(dim=1, eps=1e-08)\n",
    "    return cos(x1, x2)\n",
    "\n",
    "tau = 0.05 # from their code\n",
    "\n",
    "def loss_fn(x1, x2, x2_samples, y_samples):\n",
    "    # print('x1:')\n",
    "    # print(x1.shape)\n",
    "    # print('x2:')\n",
    "    # print(x2.shape)\n",
    "    # print('y_samples:')\n",
    "    # print(y_samples.shape)\n",
    "    # print('x2 samples:')\n",
    "    # print(x2_samples.shape)\n",
    "\n",
    "    sim = cosine_similarity(x1, x2)\n",
    "    e_term = torch.exp(sim / tau)\n",
    "    \n",
    "    sigma_term = 0\n",
    "\n",
    "    for i in range(len(y_samples)):\n",
    "        if y_samples[i].item() == 1: # skip positive pairs\n",
    "            continue\n",
    "        sigma_term = sigma_term + torch.exp(cosine_similarity(x1, model(x2_samples[i].unsqueeze(0).to(device))) / tau)\n",
    "\n",
    "    return -torch.log(e_term / (e_term + sigma_term))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, optimizer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "    image_i = 0\n",
    "\n",
    "    for batch, (x1_samples, x2_samples, y_samples) in enumerate(dataloader):\n",
    "\n",
    "        for i in range(len(y_samples)):\n",
    "            x1, x2, y = x1_samples[i].to(device), x2_samples[i].to(device), y_samples[i].to(device)\n",
    "            # print('Y Shape:')\n",
    "            # print(y_samples.shape)\n",
    "\n",
    "            # print('x1 samples Shape:')\n",
    "            # print(x1_samples.shape)\n",
    "\n",
    "            # print('x2 samples shape:')\n",
    "            # print(x2_samples.shape)\n",
    "\n",
    "            if y.item() == 0: # skip negative pairs\n",
    "                continue\n",
    "        \n",
    "            # Compute prediction and loss\n",
    "            model.train()\n",
    "            output1 = model(x1.unsqueeze(0)).to(device)\n",
    "            output2 = model(x2.unsqueeze(0)).to(device)\n",
    "\n",
    "            loss = loss_fn(output1, output2, x2_samples, y_samples).to(device)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if image_i % 1000 == 0:\n",
    "                last_loss = running_loss / 1000\n",
    "                # print('  pairs {} loss: {}'.format(image_i + 1, last_loss))\n",
    "                running_loss = 0.\n",
    "            \n",
    "            image_i += 1\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(output1, output2):\n",
    "    distance = torch.norm(output2 - output1)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_match_pairs():\n",
    "    for i in range(len(celeba_data.pairs)): # for each anchor pair\n",
    "        pair = celeba_data.get_pair(i)\n",
    "        x1 = pair[0].to(device) # anchor\n",
    "        output1 = model(x1.unsqueeze(0)).squeeze(0)\n",
    "        \n",
    "        if pair[2] == 0: # skip negative pairs\n",
    "            continue\n",
    "\n",
    "        is_smiling = celeba_data.is_smiling(i)\n",
    "\n",
    "        min_dist = 999\n",
    "        new_sample = None\n",
    "\n",
    "        # for k in range(len(celeba_data.pairs)): # for each pair except anchor and different classes\n",
    "        for k in range(10): # 10 for the demo\n",
    "            if i == k or is_smiling != celeba_data.is_smiling(k): # skip anchor and non same class\n",
    "                continue\n",
    "\n",
    "            p = celeba_data.get_pair(i)\n",
    "            x3, x4 = p[0].to(device), p[1].to(device)\n",
    "\n",
    "            output3 = model(x3.unsqueeze(0)).squeeze(0)\n",
    "            output4 = model(x4.unsqueeze(0)).squeeze(0)\n",
    "                \n",
    "            d1 = dist(output1, output3)\n",
    "            d2 = dist(output1, output4)\n",
    "\n",
    "            if d1 < min_dist:\n",
    "                min_dist = d1\n",
    "                new_sample = x3\n",
    "            \n",
    "            if d2 < min_dist:\n",
    "                min_dist = d2\n",
    "                new_sample = x4\n",
    "        \n",
    "        celeba_data.pairs[i][1] = new_sample.cpu()# replace second sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "Epoch 1 loss: 2.0091801294982434\n",
      "Running loss: 2.0091801294982434\n",
      "Match pairs updated.\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Epoch 2 loss: 1.2992919693244622\n",
      "Running loss: 1.6542360494113528\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Epoch 3 loss: 1.0160838237759018\n",
      "Running loss: 1.4415186408662024\n",
      "Match pairs updated.\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Epoch 4 loss: 0.011093031051875016\n",
      "Running loss: 1.0839122384126205\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Epoch 5 loss: 0.015930626325165134\n",
      "Running loss: 0.8703159159951295\n",
      "Match pairs updated.\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Epoch 6 loss: 0.0030656694645185495\n",
      "Running loss: 0.7257742082400277\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Epoch 7 loss: 0.004360284757895329\n",
      "Running loss: 0.6227150763140088\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/u/savo5444/srg_experiments/property_inference/rebase/MatchDG.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpusrv08/u/savo5444/srg_experiments/property_inference/rebase/MatchDG.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mRunning loss: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(running_loss \u001b[39m/\u001b[39m (t \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpusrv08/u/savo5444/srg_experiments/property_inference/rebase/MatchDG.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mif\u001b[39;00m t \u001b[39m%\u001b[39m \u001b[39m2\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpusrv08/u/savo5444/srg_experiments/property_inference/rebase/MatchDG.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39m# print('Updating match pairs...') # update match pairs\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgpusrv08/u/savo5444/srg_experiments/property_inference/rebase/MatchDG.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     update_match_pairs()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpusrv08/u/savo5444/srg_experiments/property_inference/rebase/MatchDG.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mMatch pairs updated.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpusrv08/u/savo5444/srg_experiments/property_inference/rebase/MatchDG.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# test_loop(test_dataloader, model, loss_fn)\u001b[39;00m\n",
      "\u001b[1;32m/u/savo5444/srg_experiments/property_inference/rebase/MatchDG.ipynb Cell 13\u001b[0m in \u001b[0;36mupdate_match_pairs\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpusrv08/u/savo5444/srg_experiments/property_inference/rebase/MatchDG.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m x3, x4 \u001b[39m=\u001b[39m p[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(device), p[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpusrv08/u/savo5444/srg_experiments/property_inference/rebase/MatchDG.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m output3 \u001b[39m=\u001b[39m model(x3\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m))\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgpusrv08/u/savo5444/srg_experiments/property_inference/rebase/MatchDG.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m output4 \u001b[39m=\u001b[39m model(x4\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39;49m))\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpusrv08/u/savo5444/srg_experiments/property_inference/rebase/MatchDG.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m d1 \u001b[39m=\u001b[39m dist(output1, output3)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgpusrv08/u/savo5444/srg_experiments/property_inference/rebase/MatchDG.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m d2 \u001b[39m=\u001b[39m dist(output1, output4)\n",
      "File \u001b[0;32m~/.conda/envs/phd9/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/phd9/lib/python3.9/site-packages/torchvision/models/alexnet.py:48\u001b[0m, in \u001b[0;36mAlexNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m---> 48\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures(x)\n\u001b[1;32m     49\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgpool(x)\n\u001b[1;32m     50\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/phd9/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/phd9/lib/python3.9/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/phd9/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/phd9/lib/python3.9/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/.conda/envs/phd9/lib/python3.9/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    454\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "running_loss = 0.\n",
    "\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    loss = train_loop(celeba_loader, model, optimizer)\n",
    "    print('Epoch {} loss: {}'.format(t + 1, loss))\n",
    "    running_loss += loss\n",
    "    print('Running loss: {}'.format(running_loss / (t + 1)))\n",
    "    \n",
    "\n",
    "    if t % 2 == 0:\n",
    "        # print('Updating match pairs...') # update match pairs\n",
    "        update_match_pairs()\n",
    "        print('Match pairs updated.')\n",
    "\n",
    "    # test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
